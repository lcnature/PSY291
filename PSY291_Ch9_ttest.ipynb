{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy0ryXc9UeP3FynTRnjpsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcnature/PSY291/blob/main/PSY291_Ch9_ttest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 9 t-test**\n",
        "\n",
        "## replacing an assumed known standard deviation by an estimated standard deviation\n",
        "\n",
        "When we don't know the standard deviation `σ` of a population, we can replace it by the estimate `s` based on a sample, and estimate standard error $s_M$ using `s`.\n",
        "\n",
        "Let's look at how $s_M$ is distributed\n",
        "\n",
        "For simplicity, let's assume a score `X` follows a standard normal distribution, but a researcher does not really know the standard deviation. Let's only assume that he/she knows the mean is 0.\n",
        "\n",
        "How does the estimated **standard error** for samples of size 5 look like?\n"
      ],
      "metadata": {
        "id": "DaOnMGDQCBd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4JgSUJ4B5cP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Let's simulate drawing samples of 10 for 10000 times.\n",
        "\n",
        "all_std_errs = []\n",
        "# this creates an empty list\n",
        "\n",
        "sample_size = 5\n",
        "\n",
        "for iteration in range(10000):\n",
        "  sample = norm.rvs(loc=0, scale=1, size=sample_size)\n",
        "  standard_deviation = np.std(sample, ddof=1)\n",
        "  # remember that when we estimate standard deviation from a sample, the\n",
        "  # degree of freedom is sample size minus 1. This is instructed by providing\n",
        "  # the argument ddof=1\n",
        "  standard_error = standard_deviation / np.sqrt(sample_size)\n",
        "\n",
        "  all_std_errs.append(standard_error)\n",
        "  # we append a new item into the list\n",
        "\n",
        "plt.hist(all_std_errs,bins=50)\n",
        "plt.xlabel('standard error')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The distribution of `t`, an equivalent of `z` in the case when standard error needs to be estimated.\n",
        "\n",
        "Similar to how we defined z-score for sample mean, we can now define t statistic for sample mean, with the only difference being the standard error is estimated from a sample.\n",
        "\n",
        "$$t = \\frac{M-μ}{s_M} = \\frac{\\sqrt{n}(M-μ)}{s} $$\n",
        "\n",
        "Let's look at how `t`'s distribution differs from a normal distribution, when `s` is estimated.\n"
      ],
      "metadata": {
        "id": "4u00XnCP34bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This block of code may take a minute to run\n",
        "all_degree_of_freedom = np.array([1, 2, 5, 10, 20, 50])\n",
        "all_sample_sizes = all_degree_of_freedom + 1\n",
        "# degree of freedom for t-statistic is always sample size minus 1\n",
        "\n",
        "all_colors = ['red','orange','yellow','green','blue','magenta']\n",
        "for sample_size, color in zip(all_sample_sizes, all_colors):\n",
        "  # what this does is that in each iteration of this \"for\" loop, we take\n",
        "  # a sample_size from the first list, and a color from the second list, both\n",
        "  # in sequential order. This allows us to plot each histogram with a different color.\n",
        "\n",
        "\n",
        "  all_t = []\n",
        "  for iteration in range(100000):\n",
        "    sample = norm.rvs(loc=0, scale=1.0, size=sample_size)\n",
        "    # for simplicity, we choose to simulate data from a standard normal distribution\n",
        "\n",
        "    s = np.std(sample, ddof=1)\n",
        "    # this is the estimated standard deviation of the sample\n",
        "\n",
        "    se = s / np.sqrt(sample_size)\n",
        "    # this is the estimated standard error\n",
        "\n",
        "    t = (np.mean(sample) - 0) / se\n",
        "\n",
        "    all_t.append(t)\n",
        "    # we append the t-statistic estimated from each sample\n",
        "\n",
        "\n",
        "  plt.hist(all_t, bins=np.arange(-6,6.1,0.1),\n",
        "           histtype='step', density=True,ec=color)\n",
        "  plt.xlabel('t-statistic')\n",
        "  plt.ylabel('count')\n",
        "  plt.xlim([-6,6])\n",
        "\n",
        "\n",
        "# let's then compare these histograms against the standard normal distribution,\n",
        "# which is how z-score should be distributed\n",
        "x = np.arange(-6, 6.1, 0.1)\n",
        "y = norm.pdf(x)\n",
        "plt.plot(x, y, '--k')\n",
        "plt.legend(['t: df={}'.format(df) for df in all_degree_of_freedom] + ['standard normal'])\n",
        "plt.ylabel('density')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7D4KNGWj7CLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate effect size\n",
        "\n",
        "### Cohen's d\n",
        "\n"
      ],
      "metadata": {
        "id": "duK3yP7NNff_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "scores = [39, 41, 43, 45, 46, 47, 50, 51, 52]\n",
        "mu = 50\n",
        "\n",
        "d = (np.mean(scores) - mu) / np.std(scores, ddof=1)\n",
        "print('Cohen''s d for this sample based on a null hypothesis of mu=50:')\n",
        "print(d)"
      ],
      "metadata": {
        "id": "loKji60D3dey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $r^2$: variance explainable by treatment effect"
      ],
      "metadata": {
        "id": "XBy8Dc9TPKGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "scores = np.array([39, 41, 43, 45, 46, 47, 50, 51, 52])\n",
        "mu = 50\n",
        "\n",
        "total_var = np.sum((scores-mu) ** 2)\n",
        "var_residual = np.sum((scores-np.mean(scores)) ** 2)\n",
        "\n",
        "r2 = 1 - var_residual / total_var\n",
        "# This is equivalent to the equation in our lecture note\n",
        "\n",
        "print('r2 is', r2)"
      ],
      "metadata": {
        "id": "XWUoM9zeO6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate confidence interval\n",
        "\n",
        "For the example above, we can use t-distribution implemented in scipy.stats to calculate confidence interval\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sLGjzO51P33b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import t as t_dist\n",
        "# We rename the module t inside our code just in case we redefine t for something else\n",
        "\n",
        "confidence_level = 0.95\n",
        "t_edge_left = t_dist.ppf((1-confidence_level)/2, df=len(scores)-1)\n",
        "# ppf is the inverse of cumulative distribution function.\n",
        "# we first find the size of each tail on both sides of he 95% confidence interval\n",
        "# of the t-distribution. Note that we need to specify degree of freedom, df\n",
        "\n",
        "# Since t-distribution is symmetric\n",
        "t_edge_right = - t_edge_left\n",
        "\n",
        "# Remember we have to calculate standard error, not just standard deviation\n",
        "se = np.std(scores, ddof=1) / np.sqrt(len(scores))\n",
        "\n",
        "CI = [np.mean(scores) + se * t_edge_left, np.mean(scores) + se * t_edge_right]\n",
        "\n",
        "print('95% CI:',CI)\n",
        "\n"
      ],
      "metadata": {
        "id": "ce55JSjyP17F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing t-test in the real world\n",
        "\n",
        "Since t-test is used so frequently, it has been well implemented that we can run in just one single line of code!\n",
        "\n",
        "We are testing against the null hypothesis that the mean of the population is 50.\n",
        "\n",
        "So we need to tell the function of t-test this number, together with all the scores in our sample. That's all!\n",
        "\n",
        "Check out the document [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n"
      ],
      "metadata": {
        "id": "vrXyAlr0cliH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "# ttest_1samp stands for one-sample t-test, which is what we learned today.\n",
        "# We will learn about t-test between two samples in the next class.\n",
        "\n",
        "mu = 50\n",
        "# this is the mean of null hypothesis that we are testing against\n",
        "# scores is the scores in our sample\n",
        "result = ttest_1samp(scores, popmean=mu)\n",
        "print(result)\n",
        "\n",
        "# we can also calculate confidence interval for any confidence level:\n",
        "# For example,\n",
        "print('80% CI:',result.confidence_interval(confidence_level=0.8))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fwhuvStKPrIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice\n",
        "\n",
        "Perform a one-tailed t-test to draw a conclusion of whether the following sample provides sufficient evidence that the population mean is larger than 0:\n",
        "\n",
        "scores = [-2, -1, -1, 1, 2, 2, 4, 5, 6]\n",
        "\n",
        "calculate the p-value, Cohen's d (against a hypothesized mean of 0), and confidence interval at confidence level of 95%"
      ],
      "metadata": {
        "id": "vEl2em0Fjp-5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQ66xaCVdW4t"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}